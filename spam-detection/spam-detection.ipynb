{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Naive Bayes spam filter using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "In this step, we load the data from the file. Each sample is a single line in the file and has the following format\n",
    "\n",
    "*{spam_or_ham},{email_text}*\n",
    "\n",
    "The first part is the label that identifies whether the email is spam or ham (not spam), followed by the email text. For example:\n",
    "\n",
    "`Spam,<p>But few feere in nor revellers in pride the a. Ear fathers yes begun revellers blazon one but not of take high. In had his her satiety alone fulness he sins perchance in thence climes nine scorching weary drugged...`\n",
    "\n",
    "The data will be loaded into two lists. features - the raw text of the emails, and labels - 0 (ham) or 1 (spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spam,<p>But could then once pomp to nor that glee glorious of deigned. The vexed times childe none native. To he vast now in to sore nor flow and most fabled. The few tis to loved vexed and all yet yea childe. Fulness consecrate of it before his a a a that.</p><p>Mirthful and and pangs wrong. Objects isle with partings ancient made was are. Childe and gild of all had to and ofttimes made soon from to long youth way condole sore.</p>',\n",
       " 'Spam,<p>His honeyed and land vile are so and native from ah to ah it like flash in not. That gild by in basked they lemans passed way who talethis forgot deigned nor friends his before strange. Found long little the. Talethis have soon of hellas had he. But suffice een had men in things ah love was childe through prose men bade. Now she break in shamed his brow loved spent he vaunted him that yea a. Where chill thy rake might to spoiled wassailers but breast loathed maddest but a breast cell since disappointed childe. From sad lurked lowly now was was and all present to of.</p><p>Blast adieu dome and thy the. None soon where dwell or noontide ungodly but her there later into this mote smile would his bidding would. For in holy beyond atonement. Did seemed formed to passed deem his change dwelt saw to flash. His wight mine he said adversity old his days made his.</p>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(path):\n",
    "    \"\"\"\n",
    "    read and return all data in a file\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "data_path = \"data/SpamDetectionData.txt\"\n",
    "all_data = read_file(data_path)\n",
    "all_lines = all_data.split('\\n')\n",
    "all_lines[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to see the type <class 'list'>\n",
      "total no. of samples: 2100\n",
      "total no. of features: 2100\n",
      "total no. of spam samples: 1043\n",
      "total no. of ham samples: 1057\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def read_file(path):\n",
    "    \"\"\"\n",
    "    read and return all data in a file\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    load and return the data in features and labels lists\n",
    "    each item in features contains the raw email text\n",
    "    each item in labels is either 1(spam) or 0(ham) and identifies corresponding item in features\n",
    "    \"\"\"\n",
    "    # load all data from file\n",
    "    data_path = \"data/SpamDetectionData.txt\"\n",
    "    all_data = read_file(data_path)\n",
    "    \n",
    "    # split the data into lines, each line is a single sample\n",
    "    all_lines = all_data.split('\\n')\n",
    "    print(\"to see the type\", type(all_lines))\n",
    "    # each line in the file is a sample and has the following format\n",
    "   \n",
    "    \n",
    "    # extract the feature (email text) and label (spam or ham) from each line\n",
    "    features = []\n",
    "    labels = []\n",
    "    for line in all_lines:\n",
    "        if line[0:4] == 'Spam':\n",
    "            labels.append(1)\n",
    "            features.append(line[5:])\n",
    "            pass\n",
    "        elif line[0:3] == 'Ham':\n",
    "            labels.append(0)\n",
    "            features.append(line[4:])\n",
    "           \n",
    "        else:\n",
    "            # ignore markers, empty lines and other lines that aren't valid sample\n",
    "            # print('ignore: \"{}\"'.format(line));\n",
    "            pass\n",
    "    \n",
    "    return features, labels\n",
    "    \n",
    "features, labels = load_data()\n",
    "\n",
    "print(\"total no. of samples:\",(len(labels)))\n",
    "print(\"total no. of features:\", (len(features)))\n",
    "print(\"total no. of spam samples: {}\".format(labels.count(1)))\n",
    "print(\"total no. of ham samples: {}\".format(labels.count(0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Print a random sample for inspection:\n",
      "random idx is : 1068\n",
      "example feature: <p>Master wheeled gently the some that chamber bird. Word and both this gently he i there by flutter the for i chamber. Countenance silken kind spoke sat within at his grew this vainly tempest was. Streaming a something that stern a unbrokenquit. The form and that a visiter suddenly chamber above door seeing as and and dreams angels chamber this or. Fantastic in the then still my master midnight word the all i shall it. Evilprophet was so flitting over. Uttered and at art that fast door the no a melancholy but. The answer prophet my syllable demons before. Take only disaster. If within this into head a. Of the songs flown shorn and tis saintly than into we echo you devil yet feather no. Bust word dreaming. He his and and wondering fowl mystery word violet an. Hath entrance stood heard as crest bird not cushioned forgotten now sorrowsorrow be beguiling though a he now bird.</p><p>The get the once longer thereat from what my tapping gently. Back nights the flutter. Nepenthe till over my not is said. Upon the there this at felt still then sculptured maiden lenore. I floor for bust gloated disaster swung nevermore demons muttered on prophet. That or land.</p><p>A discourse chamber with radiant songs forgiveness more. Hesitating and till or doubtless pallas and my came the did. This but with i a of tis lattice i oh. Flung visiter stately land from tempest unto word still of sad. Upon pallas an door sad was the with my syllable of this. This my ghost devil stood there sure grave made echo velvet fearing stock flirt or.</p>\n",
      "example label: 0 (ham)\n"
     ]
    }
   ],
   "source": [
    "#randomly looking at some mails\n",
    "print(\"\\nPrint a random sample for inspection:\")\n",
    "random_idx = random.randint(0, len(labels))\n",
    "print(\"random idx is :\", random_idx)\n",
    "print(\"example feature: {}\".format(features[random_idx][0:]))\n",
    "print(\"example label: {} ({})\".format(labels[random_idx],\n",
    "                                'spam' if labels[random_idx] else 'ham'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data - Split data randomly into training and test subsets\n",
    "Use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to see the type <class 'list'>\n",
      "no. of train features: 1680\n",
      "no. of train labels: 1680\n",
      "no. of test features: 420\n",
      "no. of test labels: 420\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load features and labels\n",
    "features, labels = load_data()\n",
    "\n",
    "# split data into training / test sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, \n",
    "    labels, \n",
    "    test_size=0.2,   # use 10% for testing\n",
    "    random_state=42)\n",
    "\n",
    "print(\"no. of train features: {}\".format(len(features_train)))\n",
    "print(\"no. of train labels: {}\".format(len(labels_train)))\n",
    "print(\"no. of test features: {}\".format(len(features_test)))\n",
    "print(\"no. of test labels: {}\".format(len(labels_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data - Vectorize text data\n",
    "Use [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to vectorize text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<420x782 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 68889 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorize email text into tfidf matrix\n",
    "# TfidfVectorizer converts collection of raw documents to a matrix of TF-IDF features.\n",
    "# It's equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "vectorizer = TfidfVectorizer()\n",
    "    #input='content',     # input is actual text\n",
    "    #lowercase=True,      # convert to lower case before tokenizing\n",
    "    #stop_words='english' # remove stop words\n",
    "\n",
    "features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "features_test_transformed  = vectorizer.transform(features_test)\n",
    "#We only use transform() on the test data because we use the scaling paramaters\n",
    "#learned on the train data to scale the test data. \n",
    "features_test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Naive Bayes Classifier\n",
    "Use [MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) to train a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier accuracy 1.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import \n",
    "import pickle\n",
    "\n",
    "def save(vectorizer, classifier):\n",
    "    '''\n",
    "    save classifier to disk\n",
    "    '''\n",
    "    with open('model.pkl', 'wb') as file:\n",
    "        pickle.dump((vectorizer, classifier), file)\n",
    "        \n",
    "def load():\n",
    "    '''\n",
    "    load classifier from disk\n",
    "    '''\n",
    "    with open('model.pkl', 'rb') as file:\n",
    "        vectorizer, classifier = pickle.load(file)\n",
    "    return vectorizer, classifier\n",
    "\n",
    "# train a classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(features_train_transformed, labels_train)\n",
    "\n",
    "# save the trained model\n",
    "save(vectorizer, classifier)\n",
    "\n",
    "# score the classifier accuracy\n",
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(\n",
    "    features_test_transformed, labels_test) * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate F1 Score\n",
    "Calculate [F1 score](https://en.wikipedia.org/wiki/F1_score) using [sklearn metrics.f1_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score 1.00\n",
      "[0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1\n",
      " 0 0 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1\n",
      " 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0\n",
      " 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0\n",
      " 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0\n",
      " 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0\n",
      " 0 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 0 1\n",
      " 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0\n",
      " 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0\n",
      " 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 1 1\n",
      " 0 1 0 0 1 1 0 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "prediction = classifier.predict(features_test_transformed)\n",
    "fscore = metrics.f1_score(labels_test, prediction, average='macro')\n",
    "print(\"F score {:.2f}\".format(fscore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the trained classifier for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perform a test\n",
      "EMAIL: ['<p>And once that. His eyes but tapping tempest or shore clasp other me bird perched murmured nothing fancy was caught. And with the the get. Lenore and pallas that nothing. Beast napping my hope i pondered back lamplight its pallas that this it nameless above. Flown came perfumed nevermore answer fiend by door and being tempter fluttered of startled. Into a whether in was fancy bird came more. Lenore this fiend chamber stock floor tempest my disaster all gently thing his surely burden this devil bird. Peering swung my that and bird on back tapping with back be once f']\n",
      "The email is HAM\n"
     ]
    }
   ],
   "source": [
    "vectorizer, classifer = load()\n",
    "\n",
    "print('\\nPerform a test')                    \n",
    "#email_input = 'enter your email here'\n",
    "email_input = ['<p>And once that. His eyes but tapping tempest or shore clasp other me bird perched murmured nothing fancy was caught. And with the the get. Lenore and pallas that nothing. Beast napping my hope i pondered back lamplight its pallas that this it nameless above. Flown came perfumed nevermore answer fiend by door and being tempter fluttered of startled. Into a whether in was fancy bird came more. Lenore this fiend chamber stock floor tempest my disaster all gently thing his surely burden this devil bird. Peering swung my that and bird on back tapping with back be once f']\n",
    "#email_input=['Fiend this have thy and my forget thrilled or. The at ungainly followed and we still in above flirt unbrokenquit bust silken. Is something discourse flitting shadow the and tis. Nearly stillness plume lining the. Raven me of the. Louder smiling flutter shall more and one surcease scarce and so smiling i that into fiery. Implore before is here once door wandering suddenly spoken and the.</p><p>No presently velvet still at i pallas plainly swung my tapping was fantastic. Aptly stronger oer chamber this and. Beguiling the leave we something ease lie is. And sculptured door songs came is this of your my then of for tapping soul late raven whose sainted. Morrow murmured more more this surely he of with thy lies my door forget i have cushions. Stronger more by implore this there sat burning farther the and. It door and of said my whom this. Tinkled quoth the rapping shaven off to. Tis utters tufted']\n",
    "email_input_transformed = vectorizer.transform(email_input)\n",
    "prediction = classifer.predict(email_input_transformed)\n",
    "\n",
    "print('EMAIL:', email_input)\n",
    "print('The email is', 'SPAM' if prediction else 'HAM')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perform a test\n",
      "EMAIL: ['<p>running adversity childe he dear disporting sought fellow longdeserted a true on. Low loved had lines sighed childe the shameless. Glorious of nor sister to or forgot the waste and aye wrong chttery bad win</p>']\n",
      "The email is SPAM\n"
     ]
    }
   ],
   "source": [
    "vectorizer, classifer = load()\n",
    "\n",
    "print('\\nPerform a test')                    \n",
    "#email_input = 'enter your email here'\n",
    "email_input = ['<p>running adversity childe he dear disporting sought fellow longdeserted a true on. Low loved had lines sighed childe the shameless. Glorious of nor sister to or forgot the waste and aye wrong chttery bad win</p>']\n",
    "email_input_transformed = vectorizer.transform(email_input)\n",
    "prediction = classifer.predict(email_input_transformed)\n",
    "\n",
    "print('EMAIL:', email_input)\n",
    "print('The email is', 'SPAM' if prediction else 'HAM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
